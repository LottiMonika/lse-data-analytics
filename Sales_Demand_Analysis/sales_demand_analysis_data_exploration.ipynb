{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c700b4d1-4296-451c-b5c3-59dcec962e11",
      "metadata": {
        "id": "c700b4d1-4296-451c-b5c3-59dcec962e11"
      },
      "source": [
        "### Import libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13aa19de-16d5-4efb-afa2-595be5f26a29",
      "metadata": {
        "id": "13aa19de-16d5-4efb-afa2-595be5f26a29"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import seaborn as sns\n",
        "import re\n",
        "import calendar\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b84e4546-254e-46b9-8218-ad7a88a7791d",
      "metadata": {
        "id": "b84e4546-254e-46b9-8218-ad7a88a7791d"
      },
      "source": [
        "### Create functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55ec5fc0-59c6-411d-8d8c-66356a55ead0",
      "metadata": {
        "id": "55ec5fc0-59c6-411d-8d8c-66356a55ead0"
      },
      "outputs": [],
      "source": [
        "# Standard vertical bar chart function.\n",
        "def standard_vertical_bar_chart(df, x, y, title=\"Bar Chart\", x_label=None, y_label=None,\n",
        "                                figsize=(10,6), legend_title=None, **kwargs):\n",
        "    \"\"\"\n",
        "    Create and display a vertical bar chart from a DataFrame, save the plot as a PNG file.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df: pandas.DataFrame\n",
        "        The DataFrame containing the data to plot.\n",
        "    x: str\n",
        "        The column name to use for the x-axis.\n",
        "    y: str\n",
        "        The column name to use for the y-axis.\n",
        "    title: str, optional\n",
        "        The title of the plot (default is \"Bar Chart\").\n",
        "    x_label: str or None, optional\n",
        "        Label for the x-axis. If None, no label is set.\n",
        "    y_label: str or None, optional\n",
        "        Label for the y-axis. If None, no label is set.\n",
        "    figsize: tuple, optional\n",
        "        Figure size in inches (width, height), default is (10, 6).\n",
        "    legend_title: str or None, optional\n",
        "        Title for the legend, if a legend is present.\n",
        "    **kwargs: dict\n",
        "        Additional keyword arguments to pass to seaborn.barplot.\n",
        "\n",
        "    Saves:\n",
        "    -------\n",
        "    A PNG image of the plot, named based on the title.\n",
        "\n",
        "    Displays:\n",
        "    ---------\n",
        "    The generated vertical bar chart.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create the bar chart.\n",
        "    plt.figure(figsize=figsize)\n",
        "    sns.barplot(data=df, x=x, y=y, **kwargs)\n",
        "\n",
        "    # Get the axes so that the legend part of this function works.\n",
        "    ax = plt.gca()\n",
        "\n",
        "    # Plot the title, x and y labels, and rotate the x axis labels.\n",
        "    plt.title(title)\n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    # Add a legend if there are handles.\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "    if handles:\n",
        "        plt.legend(handles, labels, title=legend_title, loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
        "\n",
        "    # Save the figure using the title of the plot.\n",
        "    clean_title = re.sub(r'[^\\w\\s-]', '', title.replace(\"\\n\", \" \")).strip().replace(' ', '_').lower()\n",
        "    filename = f\"{clean_title}.png\"\n",
        "\n",
        "    plt.savefig(filename, dpi=500, bbox_inches=\"tight\")\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d51348e",
      "metadata": {
        "id": "6d51348e"
      },
      "outputs": [],
      "source": [
        "# Standard horizontal bar chart function.\n",
        "def standard_horizontal_bar_chart(df, x, y, title=\"Bar Chart\", x_label=None, y_label=None,\n",
        "                                  figsize=(10,6), legend_title=None, **kwargs):\n",
        "    \"\"\"\n",
        "    Create and display a horizontal bar chart from a DataFrame, save the plot as a PNG file.\n",
        "\n",
        "    Bars are sorted in descending order by the y-values, with the largest bar at the top.\n",
        "    If a palette name is provided, the colors are reversed so the largest bar is darkest.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df: pandas.DataFrame\n",
        "        The DataFrame containing the data to plot.\n",
        "    x: str\n",
        "        The column name to use for the y-axis (bars).\n",
        "    y: str\n",
        "        The column name to use for the x-axis (bar lengths).\n",
        "    title: str, optional\n",
        "        The title of the plot (default is \"Bar Chart\").\n",
        "    x_label: str or None, optional\n",
        "        Label for the y-axis. If None, no label is set.\n",
        "    y_label: str or None, optional\n",
        "        Label for the x-axis. If None, no label is set.\n",
        "    figsize: tuple, optional\n",
        "        Figure size in inches (width, height), default is (10, 6).\n",
        "    legend_title: str or None, optional\n",
        "        Title for the legend, if a legend is present.\n",
        "    **kwargs: dict\n",
        "        Additional keyword arguments to pass to seaborn.barplot.\n",
        "\n",
        "    Saves:\n",
        "    -------\n",
        "    A PNG image of the plot, named based on the title.\n",
        "\n",
        "    Displays:\n",
        "    ---------\n",
        "    The generated horizontal bar chart.\n",
        "    \"\"\"\n",
        "\n",
        "    # Sort by descending value so largest is on top\n",
        "    df_sorted = df.sort_values(by=y, ascending=False)\n",
        "\n",
        "    # Reverse the palette so that the first bar (top = largest) is darkest\n",
        "    if 'palette' in kwargs and isinstance(kwargs['palette'], str):\n",
        "        palette_name = kwargs['palette']\n",
        "        kwargs['palette'] = sns.color_palette(palette_name, len(df_sorted))[::-1]\n",
        "\n",
        "    # Create the bar chart.\n",
        "    plt.figure(figsize=figsize)\n",
        "    sns.barplot(data=df_sorted, x=y, y=x, **kwargs)\n",
        "\n",
        "    ax = plt.gca()\n",
        "\n",
        "    # Plot the title, x and y labels, and rotate the x axis labels.\n",
        "    plt.title(title)\n",
        "    plt.xlabel(y_label)\n",
        "    plt.ylabel(x_label)\n",
        "    plt.xticks(rotation=0)\n",
        "\n",
        "    # Add a legend if needed\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "    if handles:\n",
        "        plt.legend(handles, labels, title=legend_title, loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the figure using the title\n",
        "    clean_title = re.sub(r'[^\\w\\s-]', '', title.replace(\"\\n\", \" \")).strip().replace(' ', '_').lower()\n",
        "    filename = f\"{clean_title}.png\"\n",
        "    plt.savefig(filename, dpi=500, bbox_inches=\"tight\")\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd6529b3",
      "metadata": {
        "id": "dd6529b3"
      },
      "source": [
        "### Load all data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcaa222e",
      "metadata": {
        "id": "bcaa222e"
      },
      "outputs": [],
      "source": [
        "# Load provided data, including filtered ones.\n",
        "sales = pd.read_csv('sales.csv')\n",
        "temperatures = pd.read_csv('temperatures.csv')\n",
        "filtered_sales = pd.read_csv('filtered_sales.csv')\n",
        "filtered_sales_temp = pd.read_csv('filtered_sales_temp.csv')\n",
        "\n",
        "# Load City's holiday calendar.\n",
        "holidays = pd.read_csv('calendario.csv',\n",
        "                       sep=';',\n",
        "                       parse_dates=['Dia'],\n",
        "                      dayfirst=True)\n",
        "\n",
        "# Load sport's match calendar.\n",
        "sport = pd.read_csv('Allcity_sport.csv',\n",
        "                     parse_dates=['Date'],\n",
        "                    dayfirst=True)\n",
        "\n",
        "# Load sport1's match calendar.\n",
        "sport1 = pd.read_csv('International_city_country.csv',\n",
        "                    parse_dates=['Date'],\n",
        "                    dayfirst=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "832144ad",
      "metadata": {
        "id": "832144ad"
      },
      "source": [
        "### Exploratory analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc47758e-737a-4183-b2f3-8813d72b3e35",
      "metadata": {
        "id": "bc47758e-737a-4183-b2f3-8813d72b3e35"
      },
      "source": [
        "#### The below only includes visualisations that were used in either or both the presentation and technical report and that were created using Python. All other exploratory visualisation were created using Tableau and can be viewed in the Tableau workbook.\n",
        "\n",
        "#### You'll also find below the code used to create new columns/data frames that were used to create visualisations in Tableau."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c725d054-16c7-482d-98a2-5c6d40ad8f02",
      "metadata": {
        "id": "c725d054-16c7-482d-98a2-5c6d40ad8f02"
      },
      "source": [
        "***Adding a district/town column and creating a new data frame called filtered_sales_temp2. This file was used to create some charts in Tableau.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccde1c64-7521-4d83-a25a-0b41716dd6a6",
      "metadata": {
        "id": "ccde1c64-7521-4d83-a25a-0b41716dd6a6"
      },
      "outputs": [],
      "source": [
        "# Add a district/town column to filtered_sales_temp.\n",
        "# Create a district/town dictionary.\n",
        "district_town_dict = {'removed to ensure anonymity of employer'}\n",
        "\n",
        "filtered_sales_temp['district/town'] = filtered_sales_temp['postcode'].replace(district_town_dict)\n",
        "filtered_sales_temp.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb8c825a-3caf-4a22-8230-e5fe957b2e8c",
      "metadata": {
        "id": "cb8c825a-3caf-4a22-8230-e5fe957b2e8c"
      },
      "outputs": [],
      "source": [
        "# View district/town unique values.\n",
        "filtered_sales_temp['district/town'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ca73cde-32ab-4137-9192-21651939fad2",
      "metadata": {
        "id": "9ca73cde-32ab-4137-9192-21651939fad2"
      },
      "outputs": [],
      "source": [
        "# Check for nulls in the district/town column.\n",
        "filtered_sales_temp['district/town'].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "396cede2-7447-4308-9dc4-937df918b0f6",
      "metadata": {
        "id": "396cede2-7447-4308-9dc4-937df918b0f6"
      },
      "outputs": [],
      "source": [
        "# Drop town/city column.\n",
        "filtered_sales_temp.drop(columns='town/city', inplace=True)\n",
        "\n",
        "# View columns.\n",
        "filtered_sales_temp.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f44d5664-6d8e-4b04-8eb4-080a305d94c8",
      "metadata": {
        "id": "f44d5664-6d8e-4b04-8eb4-080a305d94c8"
      },
      "outputs": [],
      "source": [
        "# Move the district/town column to be the second column.\n",
        "col = filtered_sales_temp.pop('district/town')\n",
        "filtered_sales_temp.insert(1, 'district/town', col)\n",
        "filtered_sales_temp.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a969acf-27f5-4890-bc24-daa28909b74c",
      "metadata": {
        "id": "1a969acf-27f5-4890-bc24-daa28909b74c"
      },
      "outputs": [],
      "source": [
        "# Save just postcode and district/town as a dataframe (to be used when joining to file in Tableau).\n",
        "district_town_postcode = filtered_sales_temp[['district/town', 'postcode']].drop_duplicates()\n",
        "district_town_postcode.to_csv('district_town_postcode.csv', index=False)\n",
        "\n",
        "# Save dataframe with district/town column in a new csv.\n",
        "filtered_sales_temp.to_csv('filtered_sales_temp2.csv', index=False)\n",
        "\n",
        "# Create a copy of filtered_sales_temp and rename it filtered_sales_temp2 so it matches the csv file name.\n",
        "filtered_sales_temp2 = filtered_sales_temp.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b20c65bb-a290-4131-82a2-f9e331c30a3b",
      "metadata": {
        "id": "b20c65bb-a290-4131-82a2-f9e331c30a3b"
      },
      "source": [
        "***Creating a new data frame with the percentage of days that had no sales. This data frame was used in Tableau to create a map visual.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50b66d54-3868-45b7-82da-8ccf3bf886c0",
      "metadata": {
        "id": "50b66d54-3868-45b7-82da-8ccf3bf886c0"
      },
      "outputs": [],
      "source": [
        "# Filter to only rows where sold_units > 0.\n",
        "df_sales_all = filtered_sales_temp[filtered_sales_temp['sold_units'] > 0]\n",
        "\n",
        "# Group by petrol_station and count unique dates.\n",
        "sales_days_count_all = df_sales_all.groupby('petrol_station')['date'].nunique().reset_index()\n",
        "\n",
        "# Rename \"date\" to 'no_sales_count'.\n",
        "sales_days_count_all.rename(columns={'date':'n_days_sales'}, inplace=True)\n",
        "\n",
        "# Sort by 'sales_count' descending.\n",
        "sales_days_count_all = sales_days_count_all.sort_values(by='n_days_sales', ascending=True)\n",
        "\n",
        "# View no_sales_days_count\n",
        "sales_days_count_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c218d74-4178-4bb9-80bb-8bd6471aa11d",
      "metadata": {
        "id": "4c218d74-4178-4bb9-80bb-8bd6471aa11d"
      },
      "outputs": [],
      "source": [
        "# Create a percentage column.\n",
        "sales_days_count_all['percentage'] = (sales_days_count_all['n_days_sales'])/(713)*100\n",
        "\n",
        "# Round the percentage column to 2 decimal places.\n",
        "sales_days_count_all['percentage'] = sales_days_count_all['percentage'].round(2)\n",
        "\n",
        "# View sales_days_count_all\n",
        "sales_days_count_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f7f3d9f-e2b5-4532-b9df-76c400fcae4d",
      "metadata": {
        "id": "8f7f3d9f-e2b5-4532-b9df-76c400fcae4d"
      },
      "outputs": [],
      "source": [
        "# Save as a csv to use in a map visual in Tableau.\n",
        "sales_days_count_all.to_csv('sales_days_count.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7218517-2483-44d2-a578-95533a667aab",
      "metadata": {
        "id": "b7218517-2483-44d2-a578-95533a667aab"
      },
      "source": [
        "***Creating a bar chart with error bars on the different event/holiday categories. This chart was used in the technical report.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "227ecc50-1ae5-43af-ba09-55c3aabeb4a7",
      "metadata": {
        "id": "227ecc50-1ae5-43af-ba09-55c3aabeb4a7"
      },
      "outputs": [],
      "source": [
        "# Convert date column in filtered_sales_temp2 into datetime.\n",
        "filtered_sales_temp2['date'] = pd.to_datetime(filtered_sales_temp2['date'])\n",
        "filtered_sales_temp2.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71517e74-ecdb-4664-8119-be51d988ee45",
      "metadata": {
        "id": "71517e74-ecdb-4664-8119-be51d988ee45"
      },
      "outputs": [],
      "source": [
        "# Rename 'Date' columns in sport events to lower case.\n",
        "sport.rename(columns={'Date': 'date'}, inplace=True)\n",
        "sport1.rename(columns={'Date': 'date'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62d8ebe3-8f9c-428c-9c86-15ee8e0cce62",
      "metadata": {
        "id": "62d8ebe3-8f9c-428c-9c86-15ee8e0cce62"
      },
      "outputs": [],
      "source": [
        "# Rename the 'X' column in holidays to 'date'.\n",
        "holidays.rename(columns={'X': 'date'}, inplace=True)\n",
        "holidays.rename(columns={'Y': 'holiday_name'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fca81545-6c87-4ad1-b759-37a60bcf34d5",
      "metadata": {
        "id": "fca81545-6c87-4ad1-b759-37a60bcf34d5"
      },
      "outputs": [],
      "source": [
        "# Drop unnecessary columns in holidays.\n",
        "holidays = holidays.drop(['removed to ensure anonymity of employer'], axis=1)\n",
        "holidays.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01c824c1-83d8-426c-afa4-5b69aace31d2",
      "metadata": {
        "id": "01c824c1-83d8-426c-afa4-5b69aace31d2"
      },
      "outputs": [],
      "source": [
        "# Drop unnecessary columns in sport events.\n",
        "sport = sport.drop(['Round Number', 'Location', 'Home Team', 'Away Team', 'Result'], axis=1)\n",
        "sport.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd7fe18c-dec1-4025-bd97-57f5a0d560a8",
      "metadata": {
        "id": "bd7fe18c-dec1-4025-bd97-57f5a0d560a8"
      },
      "outputs": [],
      "source": [
        "# Drop unnecessary columns in sport events.\n",
        "sport1 = sport1.drop(['Round Number', 'Unnamed: 2', 'Location', 'Home Team', 'Away Team', 'Group', 'Result'], axis=1)\n",
        "sport1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d5d7517-4fe1-44e2-88d4-e7b6f82eb256",
      "metadata": {
        "id": "3d5d7517-4fe1-44e2-88d4-e7b6f82eb256"
      },
      "outputs": [],
      "source": [
        "# Drop duplicates.\n",
        "holidays = holidays.drop_duplicates(subset='date')\n",
        "sport = sport.drop_duplicates(subset='date')\n",
        "sport1 = sport1.drop_duplicates(subset='date')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99d24df9-2463-42c2-aed2-151415de470c",
      "metadata": {
        "id": "99d24df9-2463-42c2-aed2-151415de470c"
      },
      "outputs": [],
      "source": [
        "# Create a new dataframe and merge the three external datasets into filtered_sales_temp2.\n",
        "filtered_sales_temp3 = filtered_sales_temp2.merge(holidays, on='date', how='left') \\\n",
        "         .merge(sport, on='date', how='left') \\\n",
        "         .merge(sport1, on='date', how='left')\n",
        "\n",
        "filtered_sales_temp3.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "396b1500-0d7a-489b-a1be-ef7b9aeb2497",
      "metadata": {
        "id": "396b1500-0d7a-489b-a1be-ef7b9aeb2497"
      },
      "outputs": [],
      "source": [
        "# Rename the Matches columns accordingly.\n",
        "filtered_sales_temp3.rename(columns={'Number_x': 'sport_match'}, inplace=True)\n",
        "filtered_sales_temp3.rename(columns={'Number_y': 'sport1_match'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7eecd528-c63b-4aa1-9353-404b70a6302d",
      "metadata": {
        "id": "7eecd528-c63b-4aa1-9353-404b70a6302d"
      },
      "outputs": [],
      "source": [
        "# Convert to Boolean: True if value is not null, else False.\n",
        "filtered_sales_temp3['is_holiday'] = filtered_sales_temp3['holiday_name'].notna()\n",
        "filtered_sales_temp3['is_sport'] = filtered_sales_temp3['sport_match'].notna()\n",
        "filtered_sales_temp3['is_sport1'] = filtered_sales_temp3['sport1_match'].notna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf56fce3-e43a-4dd2-9481-6c9858e6b817",
      "metadata": {
        "id": "cf56fce3-e43a-4dd2-9481-6c9858e6b817"
      },
      "outputs": [],
      "source": [
        "# Combine sport_match and sport1_match into 1 single column.\n",
        "filtered_sales_temp3['is_match'] = filtered_sales_temp3['is_sport'] | filtered_sales_temp3['is_sport1']\n",
        "filtered_sales_temp3.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2333be8a-b95d-43ee-b8ac-5f4213a0de5f",
      "metadata": {
        "id": "2333be8a-b95d-43ee-b8ac-5f4213a0de5f"
      },
      "outputs": [],
      "source": [
        "# Define event category.\n",
        "def classify_event(row):\n",
        "    if row['is_holiday'] and row['is_match']:\n",
        "        return 'Both'\n",
        "    elif row['is_holiday']:\n",
        "        return 'Holiday only'\n",
        "    elif row['is_match']:\n",
        "        return 'Match only'\n",
        "    else:\n",
        "        return 'No event'\n",
        "\n",
        "filtered_sales_temp3['event_category'] = filtered_sales_temp3.apply(classify_event, axis=1)\n",
        "\n",
        "# Print uplift summary (mean sales per category).\n",
        "uplift_summary = (\n",
        "    filtered_sales_temp3.groupby('event_category')['sold_units']\n",
        "      .agg(['count', 'mean', 'std'])\n",
        "      .reindex(['No event', 'Holiday only', 'Match only', 'Both'])\n",
        "      .reset_index()\n",
        ")\n",
        "\n",
        "print('Average Sales per Event Category:\\n')\n",
        "print(uplift_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56448f78-877a-4ad5-a3b1-7f5ac1cbe075",
      "metadata": {
        "id": "56448f78-877a-4ad5-a3b1-7f5ac1cbe075"
      },
      "outputs": [],
      "source": [
        "# Create bar chart with error bars showing the baseline, absolute sales, and uplift percentages.\n",
        "baseline = uplift_summary[uplift_summary['event_category'] == 'No event']['mean'].values[0]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(\n",
        "    data=uplift_summary,\n",
        "    x='event_category',\n",
        "    y='mean',\n",
        "    yerr=uplift_summary['std'],\n",
        "    color='skyblue',\n",
        "    capsize=0.2)\n",
        "\n",
        "# Add baseline reference line.\n",
        "plt.axhline(y=baseline, color='gray', linestyle='--', linewidth=1.5, alpha=0.6)\n",
        "plt.text(-0.4, baseline + 0.2, 'Baseline', color='gray', fontweight='bold', fontsize=9)\n",
        "\n",
        "# Set y-axis limit.\n",
        "ymin, ymax = plt.ylim()\n",
        "y_offset = (ymax - ymin) * 0.02\n",
        "\n",
        "# Annotate bars with absolute sales + uplift percentage.\n",
        "for i, row in uplift_summary.iterrows():\n",
        "    uplift_pct = ((row['mean'] - baseline) / baseline) * 100\n",
        "    label = f\"{row['mean']:.0f} ({uplift_pct:+.0f}%)\"\n",
        "\n",
        "    y_offset = (plt.ylim()[1] - plt.ylim()[0]) * 0.05\n",
        "    plt.text(i, row['mean'] + y_offset, label, ha='center', fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.title('Average daily sales by event category')\n",
        "plt.ylabel('Average units sold')\n",
        "plt.xlabel('Event category')\n",
        "plt.tight_layout()\n",
        "plt.savefig(fname='avg_daily_sales_by_event_category', dpi=500, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a3adc7a-25e5-404c-a8c7-abe4e5e64471",
      "metadata": {
        "id": "3a3adc7a-25e5-404c-a8c7-abe4e5e64471"
      },
      "source": [
        "**Average daily sales by event category - uplift analysis**\n",
        "- Holiday-only days drive the highest uplift in sales, with a +20% increase over non-event days — confirming holidays as a powerful demand trigger.\n",
        "- Match-only days also show a modest +3% uplift, indicating sports events influence purchasing behaviour, though to a much lesser extent.\n",
        "- Interestingly, days with both a holiday and a match do not yield the highest uplift, suggesting possible demand dilution or overlapping audience saturation.\n",
        "- This chart validates the importance of event-aware forecasting and highlights holidays as a key opportunity for targeted inventory scaling."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "135d5db3-6c5e-4a84-a63f-0c03a2110875",
      "metadata": {
        "id": "135d5db3-6c5e-4a84-a63f-0c03a2110875"
      },
      "source": [
        "***Creating a heatmap calendar. This chart was used in the presentation and technical report.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac1a6a59-18ea-4501-8e9d-e4927070be06",
      "metadata": {
        "id": "ac1a6a59-18ea-4501-8e9d-e4927070be06"
      },
      "outputs": [],
      "source": [
        "# Filter Dec 1–14 for both years.\n",
        "dec_1_14_2021 = filtered_sales_temp3[(filtered_sales_temp3['date'].dt.year == 2021) &\n",
        "(filtered_sales_temp3['date'].dt.month == 12) & (filtered_sales_temp3['date'].dt.day <= 14)]\n",
        "dec_1_14_2022 = filtered_sales_temp3[(filtered_sales_temp3['date'].dt.year == 2022) &\n",
        "(filtered_sales_temp3['date'].dt.month == 12) & (filtered_sales_temp3['date'].dt.day <= 14)]\n",
        "\n",
        "# Compute total sold units.\n",
        "total_2021 = dec_1_14_2021['sold_units'].sum()\n",
        "total_2022 = dec_1_14_2022['sold_units'].sum()\n",
        "\n",
        "# Compute uplift factor (handle divide-by-zero).\n",
        "uplift_factor = total_2022 / total_2021 if total_2021 > 0 else 1.0\n",
        "\n",
        "# Get Dec 15–31, 2021 data.\n",
        "dec_15_31_2021 = filtered_sales_temp3[(filtered_sales_temp3['date'].dt.year == 2021) &\n",
        "(filtered_sales_temp3['date'].dt.month == 12) & (filtered_sales_temp3['date'].dt.day >= 15)].copy()\n",
        "\n",
        "# Adjust date and scale sales.\n",
        "dec_15_31_2021['date'] = dec_15_31_2021['date'] + pd.DateOffset(years=1)\n",
        "dec_15_31_2021['sold_units'] = (dec_15_31_2021['sold_units'] * uplift_factor).round().astype(int)\n",
        "\n",
        "print(f\"Uplift factor applied: {uplift_factor:.2f}\")\n",
        "print(dec_15_31_2021[['date', 'sold_units']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71e87cd0-4a80-4c5c-8465-51247234e17a",
      "metadata": {
        "id": "71e87cd0-4a80-4c5c-8465-51247234e17a"
      },
      "outputs": [],
      "source": [
        "# Merge the scaled data of 15-31 Dec 2021 into another dataframe.\n",
        "full_heatmap_data = pd.concat([filtered_sales_temp3, dec_15_31_2021], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53881d73-9909-4111-8711-f656f7ce1480",
      "metadata": {
        "id": "53881d73-9909-4111-8711-f656f7ce1480"
      },
      "outputs": [],
      "source": [
        "# Extract necessary time components.\n",
        "full_heatmap_data['month'] = full_heatmap_data['date'].dt.month\n",
        "full_heatmap_data['day'] = full_heatmap_data['date'].dt.day\n",
        "full_heatmap_data['month_name'] = full_heatmap_data['date'].dt.strftime('%b')\n",
        "\n",
        "# Set desired month display order.\n",
        "month_order = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
        "               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "\n",
        "# Group by month and day to calculate total sales.\n",
        "heatmap_totals = full_heatmap_data.groupby(['month_name', 'day'])['sold_units'].sum().unstack()\n",
        "heatmap_totals = heatmap_totals.reindex(index=month_order)\n",
        "\n",
        "# Plot the heatmap showing total daily sales by day and month.\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.heatmap(\n",
        "    heatmap_totals,\n",
        "    cmap='YlGnBu',\n",
        "    linewidths=0.5,\n",
        "    annot=True,\n",
        "    fmt='.0f',\n",
        "    annot_kws={'fontsize': 9},\n",
        "    cbar_kws={'label': 'Total Units Sold'}\n",
        ")\n",
        "\n",
        "plt.title('Total Daily Sales by Day and Month (Including Estimated Data for 15–31 Dec 2022)')\n",
        "plt.xlabel('Day of Month')\n",
        "plt.ylabel('Month')\n",
        "plt.tight_layout()\n",
        "plt.savefig(fname='total_daily_sales_by_day_month', dpi=500, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ad99ca7-c0f4-48eb-8639-38d73d62d004",
      "metadata": {
        "id": "1ad99ca7-c0f4-48eb-8639-38d73d62d004"
      },
      "source": [
        "**Heatmap of total daily sales by day and month (2021-2022), including estimated data for 15-31 Dec 2022**\n",
        "- Peak sales occur in July and August, with multiple high-volume days above 50,000 units, especially mid- to late-month.\n",
        "- Sales ramp up in late spring (May to June) and decline sharply after September, highlighting strong seasonality.\n",
        "- Weekend-driven spikes are clearly visible, particularly on Fridays, Saturdays, and Sundays in summer months.\n",
        "- The estimated values for 15-31 Dec 2022 (scaled from 2021) help complete the heatmap and preserve year-end visibility, though they should be interpreted with caution.\n",
        "- Holidays like Christmas, New Year's Eve, and New Year, should not be discounted as they also drive high sales."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2b9adef-3906-4321-b7be-7c64d2b09180",
      "metadata": {
        "id": "c2b9adef-3906-4321-b7be-7c64d2b09180"
      },
      "source": [
        "***Creating calendar-style heatmaps for 2021 and 2022. These were used in the appendix of the technical report.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "130c9f67-ead0-4740-a1ef-08a89b655f45",
      "metadata": {
        "id": "130c9f67-ead0-4740-a1ef-08a89b655f45"
      },
      "outputs": [],
      "source": [
        "# Filter for 2022.\n",
        "calendar_df = filtered_sales_temp3[filtered_sales_temp3['date'].dt.year == 2022].copy()\n",
        "\n",
        "# Extract calendar components.\n",
        "calendar_df['month'] = calendar_df['date'].dt.month\n",
        "calendar_df['day'] = calendar_df['date'].dt.day\n",
        "calendar_df['weekday'] = calendar_df['date'].dt.weekday  # Monday=0\n",
        "\n",
        "# Group by date to get total units sold.\n",
        "calendar_df_grouped = calendar_df.groupby('date')['sold_units'].sum().reset_index()\n",
        "sales_by_date = calendar_df_grouped.set_index('date')['sold_units']\n",
        "\n",
        "# Create calendar-style grids for each month.\n",
        "monthly_grids = {}\n",
        "\n",
        "for month in range(1, 13):\n",
        "    # All calendar days (including spillover from prev/next month).\n",
        "    month_dates = [day for day in calendar.Calendar().itermonthdates(2022, month)]\n",
        "    grid = np.full((6, 7), np.nan)\n",
        "\n",
        "    for date in month_dates:\n",
        "        if date.year == 2022:\n",
        "            # Position: week_row and weekday column.\n",
        "            week_row = (date.day + calendar.monthrange(2022, month)[0] - 1) // 7\n",
        "            col = date.weekday()\n",
        "            if hasattr(sales_by_date.index[0], 'date'):\n",
        "                sales_by_date.index = [d.date() for d in sales_by_date.index]\n",
        "            grid[week_row, col] = sales_by_date.get(date, 0)\n",
        "\n",
        "    monthly_grids[month] = grid\n",
        "\n",
        "# Plot the full-year calendar-style heatmap.\n",
        "fig, axes = plt.subplots(4, 3, figsize=(16, 10))\n",
        "plt.subplots_adjust(hspace=0.8)\n",
        "\n",
        "for i, ax in enumerate(axes.flat, start=1):\n",
        "    if i > 12:\n",
        "        ax.axis('off')\n",
        "        continue\n",
        "    sns.heatmap(\n",
        "        monthly_grids[i],\n",
        "        ax=ax,\n",
        "        cmap='YlGnBu',\n",
        "        linewidths=0.5,\n",
        "        linecolor='white',\n",
        "        cbar=False,\n",
        "        annot=True,\n",
        "        fmt='.0f',\n",
        "        annot_kws={\"fontsize\": 7}\n",
        "    )\n",
        "    ax.set_title(calendar.month_name[i], fontweight='bold')\n",
        "    ax.set_xticks(np.arange(7) + 0.5)\n",
        "    ax.set_xticklabels(['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'], rotation=0)\n",
        "    ax.set_yticks([])\n",
        "    ax.set_yticklabels([])\n",
        "    ax.invert_yaxis()\n",
        "\n",
        "plt.suptitle('2022 Calendar-Style Sales Heatmap', fontsize=16)\n",
        "plt.savefig(fname='2022_cal_heatmap', dpi=500, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d60adf63-7bbd-4687-bac2-e055bd45cd69",
      "metadata": {
        "id": "d60adf63-7bbd-4687-bac2-e055bd45cd69"
      },
      "source": [
        "33. Create a calendar style heatmap for 2021."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64cb139f-4b7d-4157-96f3-5cd5de820949",
      "metadata": {
        "id": "64cb139f-4b7d-4157-96f3-5cd5de820949"
      },
      "outputs": [],
      "source": [
        "# Filter for 2021.\n",
        "calendar_df_2021 = filtered_sales_temp3[filtered_sales_temp3['date'].dt.year == 2021].copy()\n",
        "\n",
        "# Extract calendar components.\n",
        "calendar_df_2021['month'] = calendar_df_2021['date'].dt.month\n",
        "calendar_df_2021['day'] = calendar_df_2021['date'].dt.day\n",
        "calendar_df_2021['weekday'] = calendar_df_2021['date'].dt.weekday  # Monday=0\n",
        "\n",
        "# Group by date to get total units sold.\n",
        "calendar_df_grouped_2021 = calendar_df_2021.groupby('date')['sold_units'].sum().reset_index()\n",
        "sales_by_date_2021 = calendar_df_grouped_2021.set_index('date')['sold_units']\n",
        "\n",
        "# Ensure index is datetime.date for matching.\n",
        "if hasattr(sales_by_date_2021.index[0], 'date'):\n",
        "    sales_by_date_2021.index = [d.date() for d in sales_by_date_2021.index]\n",
        "\n",
        "# Create calendar-style grids for each month.\n",
        "monthly_grids_2021 = {}\n",
        "\n",
        "for month in range(1, 13):\n",
        "     # All calendar days (including spillover from prev/next month).\n",
        "    month_dates = [day for day in calendar.Calendar().itermonthdates(2021, month)]\n",
        "    grid = np.full((6, 7), np.nan)\n",
        "    for date in month_dates:\n",
        "        if date.year == 2021:\n",
        "            # Position: week_row and weekday column.\n",
        "            week_row = (date.day + calendar.monthrange(2021, month)[0] - 1) // 7\n",
        "            col = date.weekday()\n",
        "            grid[week_row, col] = sales_by_date_2021.get(date, 0)\n",
        "    monthly_grids_2021[month] = grid\n",
        "\n",
        "# Plot the full-year calendar-style heatmap.\n",
        "fig, axes = plt.subplots(4, 3, figsize=(16, 10))\n",
        "plt.subplots_adjust(hspace=0.8)\n",
        "\n",
        "for i, ax in enumerate(axes.flat, start=1):\n",
        "    if i > 12:\n",
        "        ax.axis('off')\n",
        "        continue\n",
        "    sns.heatmap(\n",
        "        monthly_grids_2021[i],\n",
        "        ax=ax,\n",
        "        cmap='YlGnBu',\n",
        "        linewidths=0.5,\n",
        "        linecolor='white',\n",
        "        cbar=False,\n",
        "        annot=True,\n",
        "        fmt='.0f',\n",
        "        annot_kws={\"fontsize\": 7}\n",
        "    )\n",
        "    ax.set_title(calendar.month_name[i], fontweight='bold')\n",
        "    ax.set_xticks(np.arange(7) + 0.5)\n",
        "    ax.set_xticklabels(['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'], rotation=0)\n",
        "    ax.set_yticks([])\n",
        "    ax.set_yticklabels([])\n",
        "    ax.invert_yaxis()\n",
        "\n",
        "plt.suptitle('2021 Calendar-Style Sales Heatmap', fontsize=16)\n",
        "plt.savefig(fname='2021_cal_heatmap', dpi=500, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48e4e3f9-5caf-445c-a452-47f1db95d294",
      "metadata": {
        "id": "48e4e3f9-5caf-445c-a452-47f1db95d294"
      },
      "source": [
        "***Creating weekly_city_sales and weekly_city_sales_temp data frames. These sum the total sales for each week and so can be used to create smoother time series charts. These data frames were used in Tableau.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c4b136e-d8e1-4cce-96bf-c788bbc22567",
      "metadata": {
        "id": "9c4b136e-d8e1-4cce-96bf-c788bbc22567"
      },
      "outputs": [],
      "source": [
        "# Ensure 'date' column filtered_sales_temp3 is datetime.\n",
        "filtered_sales_temp3['date'] = pd.to_datetime(filtered_sales_temp3['date'])\n",
        "\n",
        "# Group by the start of the week.\n",
        "weekly_city_sales = filtered_sales_temp3.groupby([pd.Grouper(key='date', freq='W-MON'), 'sales_location'], as_index=False).agg({\n",
        "    'sold_units': 'sum',\n",
        "    'district/town': 'first',\n",
        "    'postcode': 'first',\n",
        "    'province': 'first',\n",
        "    'month': 'first',\n",
        "    'year': 'first',\n",
        "    'season': 'first'})\n",
        "\n",
        "# Sort by date.\n",
        "weekly_city_sales.sort_values('date', inplace=True)\n",
        "\n",
        "print(weekly_city_sales.head())\n",
        "print(weekly_city_sales.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c57b37fc-cb22-4c7e-aad9-bf953335eb43",
      "metadata": {
        "id": "c57b37fc-cb22-4c7e-aad9-bf953335eb43"
      },
      "outputs": [],
      "source": [
        "# Make sure the date column is in datetime.\n",
        "weekly_city_sales['date'] = pd.to_datetime(weekly_city_sales['date'])\n",
        "weekly_city_sales.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2de9871d-f11c-4b6f-ad8d-495ad67d4ad3",
      "metadata": {
        "id": "2de9871d-f11c-4b6f-ad8d-495ad67d4ad3"
      },
      "outputs": [],
      "source": [
        "# Ensure date column in 'temperatures' is datetime.\n",
        "temperatures['date'] = pd.to_datetime(temperatures['date'])\n",
        "\n",
        "# Create a 'week_start' column for grouping.\n",
        "temperatures['week_start'] = temperatures['date'] - pd.to_timedelta(temperatures['date'].dt.weekday, unit='d')\n",
        "\n",
        "# Group by 'week_start' and average relevant columns.\n",
        "weekly_weather = temperatures.groupby('week_start', as_index=False).agg({\n",
        "    'month': 'first',\n",
        "    'year': 'first',\n",
        "    'season': 'first',\n",
        "    'avg_temp': 'mean',\n",
        "    'min_temp': 'mean',\n",
        "    'max_temp': 'mean',\n",
        "    'precip': 'mean',\n",
        "    'wind_speed': 'mean',\n",
        "    'avg_pressure': 'mean'\n",
        "})\n",
        "\n",
        "# Sort by date.\n",
        "weekly_weather.sort_values(by='week_start')\n",
        "\n",
        "# Rename week_start.\n",
        "weekly_weather.rename(columns={'week_start': 'date'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4bf0923-0e41-464a-8bd9-5997469b981c",
      "metadata": {
        "id": "b4bf0923-0e41-464a-8bd9-5997469b981c"
      },
      "outputs": [],
      "source": [
        "# Merge weekly_city_sales and weekly_weather.\n",
        "weekly_city_sales_temp = pd.merge(weekly_city_sales, weekly_weather, on='date', how='left')\n",
        "weekly_city_sales_temp.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5604f25e-aa68-4c14-804c-359682fea032",
      "metadata": {
        "id": "5604f25e-aa68-4c14-804c-359682fea032"
      },
      "outputs": [],
      "source": [
        "# Save weekly_city_sales_temp as a csv.\n",
        "weekly_city_sales_temp.to_csv('weekly_city_sales_temp.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9896ea81-d0cf-4907-8abd-8ea428d76e55",
      "metadata": {
        "id": "9896ea81-d0cf-4907-8abd-8ea428d76e55"
      },
      "source": [
        "***Creating a feature importance chart on weekly sales, temperature, and location. This was used in the presentation.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a206d252-1e74-46c2-8d23-b31050a7ccc4",
      "metadata": {
        "id": "a206d252-1e74-46c2-8d23-b31050a7ccc4"
      },
      "outputs": [],
      "source": [
        "# Encode the strings to numeric\n",
        "\n",
        "for col in ['sales_location', 'province', 'district/town']:\n",
        "    le = LabelEncoder()\n",
        "    weekly_city_sales_temp[col] = le.fit_transform(weekly_city_sales_temp[col])\n",
        "\n",
        "# Feature importance on weekly sales vs temperature vs location.\n",
        "features = ['avg_temp', 'max_temp', 'sales_location', 'province', 'district/town']\n",
        "X = weekly_city_sales_temp[features]\n",
        "y = weekly_city_sales_temp['sold_units']\n",
        "\n",
        "# Fit the Random Forest model.\n",
        "model = RandomForestRegressor()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Rename labels.\n",
        "clean_labels = {\n",
        "    'avg_temp': 'Avg temp (°C)',\n",
        "    'max_temp': 'Max temp (°C)',\n",
        "    'sales_location': 'sales_location (Encoded)',\n",
        "    'province': 'Province (Encoded)',\n",
        "    'district/town': 'District/Town (Encoded)'\n",
        "}\n",
        "\n",
        "# Map feature importance to cleaned labels.\n",
        "raw_importance = model.feature_importances_\n",
        "features_key = pd.Series(raw_importance, index=[clean_labels[f] for f in features]).sort_values(ascending=False)\n",
        "color_palette = sns.color_palette('OrRd_r', len(features_key))\n",
        "\n",
        "print('Feature Importance Ranking:')\n",
        "print(features_key)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.title('What Drives Weekly Sales Most?')\n",
        "sns.barplot(x=features_key.values, y=features_key.index, palette='OrRd_r')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.savefig(fname='what_drives_weekly_sales_most.png', dpi=500, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "948ff73c-394d-4bd5-b55a-198d10909b6e",
      "metadata": {
        "id": "948ff73c-394d-4bd5-b55a-198d10909b6e"
      },
      "source": [
        "***Creating a correlation matrix on daily sales. This was in the technical report.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b7fa1b0-82bd-4a38-b5ef-da4ac75f765b",
      "metadata": {
        "id": "2b7fa1b0-82bd-4a38-b5ef-da4ac75f765b"
      },
      "outputs": [],
      "source": [
        "# Correlation matrix for daily sales, temperature, and location features.\n",
        "# Convert location features to numeric.\n",
        "label_encoders = {}\n",
        "for col in ['province', 'district/town', 'sales_location']:\n",
        "    le = LabelEncoder()\n",
        "    filtered_sales_temp3[col] = le.fit_transform(filtered_sales_temp3[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "filtered_sales_temp3['avg_temp'] = pd.to_numeric(filtered_sales_temp3['avg_temp'], errors='coerce')\n",
        "filtered_sales_temp3['max_temp'] = pd.to_numeric(filtered_sales_temp3['max_temp'], errors='coerce')\n",
        "\n",
        "# Select relevant features.\n",
        "correlation_columns = ['sold_units', 'province', 'district/town', 'sales_location', 'avg_temp', 'max_temp']\n",
        "correlation_data = filtered_sales_temp3[correlation_columns]\n",
        "correlation_data = correlation_data.dropna()\n",
        "\n",
        "correlation_matrix_3 = correlation_data.corr()\n",
        "\n",
        "# Clean labels.\n",
        "clean_labels = {\n",
        "    'sold_units': 'Daily units Sold',\n",
        "    'province': 'Province (Encoded)',\n",
        "    'district/town': 'District/Town (Encoded)',\n",
        "    'sales_location': 'sales_location (Encoded)',\n",
        "    'avg_temp': 'Avg temp (°C)',\n",
        "    'max_temp': 'Max temp (°C)'\n",
        "}\n",
        "\n",
        "# Rename for both rows and columns.\n",
        "correlation_matrix_3.rename(index=clean_labels, columns=clean_labels, inplace=True)\n",
        "\n",
        "print('Correlation Matrix - Daily Sales, Temperature, and Location Features')\n",
        "print(correlation_matrix_3)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix_3, annot=True, cmap='Blues', fmt='.2f')\n",
        "plt.title('Correlation Matrix - Daily Sales, Temperature, and Location Features')\n",
        "plt.tight_layout()\n",
        "plt.savefig(fname='correlation_matrix_daily_sales_temp_location.png', dpi=500, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ef04181-fb18-48bf-9e21-55a256771188",
      "metadata": {
        "id": "5ef04181-fb18-48bf-9e21-55a256771188"
      },
      "source": [
        "Note: 'sales_location', 'Province', and 'District/Town' are labelled as 'Encoded' because they are categorical variables turned numeric.\n",
        "\n",
        "There is a weak positive correlation between daily sales and temperature (0.26)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff1b2c31-98a2-4fad-b12c-c38f979ec017",
      "metadata": {
        "id": "ff1b2c31-98a2-4fad-b12c-c38f979ec017"
      },
      "source": [
        "***Creating a feature importance chart on daily sales, temperature, location, and day of the week. This was used in the presentation and technical report.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36846587-e0fa-4f05-8fd3-33960b53d432",
      "metadata": {
        "id": "36846587-e0fa-4f05-8fd3-33960b53d432"
      },
      "outputs": [],
      "source": [
        "# Feature importance on daily sales vs temperature vs location vs day of week.\n",
        "features = ['province', 'district/town', 'sales_location', 'avg_temp', 'max_temp', 'day_of_week']\n",
        "X = filtered_sales_temp3[features]\n",
        "\n",
        "# Encode the strings to numeric\n",
        "for col in ['province', 'district/town', 'sales_location', 'day_of_week']:\n",
        "    le = LabelEncoder()\n",
        "    filtered_sales_temp3[col] = le.fit_transform(filtered_sales_temp3[col])\n",
        "\n",
        "# Update X after encoding\n",
        "X = filtered_sales_temp3[features]\n",
        "y = filtered_sales_temp3['sold_units']\n",
        "\n",
        "# Fit the Random Forest model.\n",
        "model = RandomForestRegressor()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Clean labels.\n",
        "clean_labels = {\n",
        "    'province': 'Province (Encoded)',\n",
        "    'district/town': 'District/Town (Encoded)',\n",
        "    'sales_location': 'sales_location (Encoded)',\n",
        "    'avg_temp': 'Avg temp (°C)',\n",
        "    'max_temp': 'Max temp (°C)',\n",
        "    'day_of_week': 'Day of week'\n",
        "}\n",
        "\n",
        "# Map feature importance to cleaned labels.\n",
        "features_key = pd.Series(model.feature_importances_, index=[clean_labels[f] for f in features]).sort_values(ascending=False)\n",
        "color_palette = sns.color_palette('Blues_r', len(features_key))\n",
        "\n",
        "print(\"Feature Importance Ranking:\")\n",
        "print(features_key)\n",
        "\n",
        "# Visualise\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.title('What Drives Daily Sales Most? (Including Day of Week)')\n",
        "sns.barplot(x=features_key.values, y=features_key.index, palette='YlGnBu_r')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.savefig(fname='what_drives_weekly_sales_most_include_dayofweek.png', dpi=500, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a533a2e0-e500-401c-a0f6-a360add0fc29",
      "metadata": {
        "id": "a533a2e0-e500-401c-a0f6-a360add0fc29"
      },
      "source": [
        "***Creating a north_south column. This new weekly_city_sales was then used to create visuals in Tableau.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b998e309-acf0-4b66-ae58-b1ebf7871497",
      "metadata": {
        "id": "b998e309-acf0-4b66-ae58-b1ebf7871497"
      },
      "outputs": [],
      "source": [
        "# Create a north_south column.\n",
        "\n",
        "north_districts = ['removed to ensure anonymity of employer']\n",
        "\n",
        "# Assign \"North\" if in the list, otherwise \"South\".\n",
        "weekly_city_sales['north_south'] = weekly_city_sales['district/town'].apply(lambda x: 'North' if x in north_districts else 'South')\n",
        "\n",
        "# View weekly_city_sales.\n",
        "weekly_city_sales.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46eba8fa-1b52-437d-9efa-889bbecc8afb",
      "metadata": {
        "id": "46eba8fa-1b52-437d-9efa-889bbecc8afb"
      },
      "outputs": [],
      "source": [
        "# Any missing values?\n",
        "weekly_city_sales['north_south'].isna().sum()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}